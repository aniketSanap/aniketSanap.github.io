{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a language model?\n",
    "\n",
    "A language model is a probability distribution over a sequence of tokens. These tokens could be words or characters or even a larger sequence. Using deep learning we will attempt to build a model which will try to predict the next token given a sequence of tokens as input. \n",
    "\n",
    "### Why is language modelling important?\n",
    "\n",
    "Computer vision had its big boom at the start of this decade with the ImageNet Large Scale Visual Recognition Challenge. Deep CNN architectures were hands down the best approach to tackle vision problems. With the use of transfer learning, these models could be used for a variety of different tasks and applications which led to rapid progress in the field of computer vision. Transfer learning is commonly used in Natural Language Processing through building a language model first and then modifying it to suite our use case. This makes sense because human language is very complex. There is no one correct approach to writing or speaking anything. When we directly train our model on a language specific task, our model has no prior information about the complex structure or any of the nuances of human language. We cannot expect a model which has just been introduced to english to perform well on any language specific task directly without understanding the language first. Hence, we train a language model on a large dataset (like wikipedia) and then use this model which has an understanding of the language on our task.\n",
    "\n",
    "### State of the art language models\n",
    "\n",
    "[OpenAI's GPT-2](https://openai.com/blog/better-language-models/) <br>\n",
    "This language model uses a very complex parallel architecture and has been trained for a long time on a tremendous amount of data. It is apparent that this language model has the capacity to fool the reader into believing that the content was actually written by a human rather than a neural network. You can play around with this model yourselves [here](https://openai.com/blog/better-language-models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
